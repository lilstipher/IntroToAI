{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "191bb19e-e65d-4610-993f-ff8a3ae8cf1f"
    }
   },
   "source": [
    " Application to PyRat Datasets (Convolutional neural network)\n",
    "--\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks were inspired by biological processes in which the connectivity pattern between neurons is inspired by the organization of the animal visual cortex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 315) (1000,)\n"
     ]
    }
   ],
   "source": [
    "#import \n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "x = np.load(\"dataset_cnn.npz\")['x']\n",
    "y = np.load(\"dataset_cnn.npz\")['y']\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create here train and test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 315) (200, 315)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#### CELL TO BE COMPLETED \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "nbpresent": {
     "id": "fbd694e3-b95c-45de-a440-a57b4e93750f"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 21, 15, 1) (800,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 19, 13, 30)        300       \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 17, 11, 60)        16260     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 8, 5, 60)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 7203      \n",
      "=================================================================\n",
      "Total params: 23,763\n",
      "Trainable params: 23,763\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(800, 21, 15, 1)\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/3\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 1.0014 - acc: 0.4400 - val_loss: 0.9771 - val_acc: 0.4150\n",
      "Epoch 2/3\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.9668 - acc: 0.5075 - val_loss: 1.0133 - val_acc: 0.4100\n",
      "Epoch 3/3\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.9347 - acc: 0.5563 - val_loss: 0.9541 - val_acc: 0.5450\n",
      "Test loss: 0.954128065109253\n",
      "Test accuracy: 0.545\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "#keras\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size =30\n",
    "num_classes = 3\n",
    "epochs = 3\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 21, 15\n",
    "\n",
    "x_train = x_train.reshape(-1,21,15,1)\n",
    "x_test = x_test.reshape(-1,21,15,1)\n",
    "input_shape = (21,15,1)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(30, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(60, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "print(x_train.shape)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 315) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#import \n",
    "\n",
    "x = np.load(\"dataset_cnn_10000.npz\")['x']\n",
    "y = np.load(\"dataset_cnn_10000.npz\")['y']\n",
    "print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test avec 10000 echantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "nbpresent": {
     "id": "4f1744ee-5d6c-46b2-9f2a-ed48d1b315ff"
    }
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "def cnn(batch_size,epochs,x_train, x_test, y_train, y_test,num_classes = 3):\n",
    "    img_rows, img_cols = 21, 15\n",
    "\n",
    "    x_train = x_train.reshape(-1,21,15,1)\n",
    "    x_test = x_test.reshape(-1,21,15,1)\n",
    "    input_shape = (21,15,1)\n",
    "\n",
    "    print(x_train.shape,y_train.shape)\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    #print(x_train.shape)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "nbpresent": {
     "id": "d2a39e02-44e7-48bd-9ba1-a273582177c0"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 315) (2000, 315)\n",
      "(8000, 21, 15, 1) (8000,)\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.9581 - acc: 0.5421 - val_loss: 0.9436 - val_acc: 0.5435\n",
      "Test loss: 0.9435920152664184\n",
      "Test accuracy: 0.5435 0.5615\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "batch_size =[1,2,3,5,10,20,30,50,70,100,200]\n",
    "num_classes = 3\n",
    "epochs = 1\n",
    "scorelist=[]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "print(x_train.shape, x_test.shape)\n",
    "for i in batch_size:\n",
    "    a=cnn(i,epochs,x_train, x_test, y_train, y_test,num_classes = 3)\n",
    "    scorelist.append(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
